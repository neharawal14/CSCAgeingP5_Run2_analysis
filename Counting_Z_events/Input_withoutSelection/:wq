import uproot
import numpy as np
import pandas as pd
import argparse
import ROOT
def read_lumi_file(year):
    input_file_name = f"/afs/cern.ch/user/n/nrawal/work/Brilcal_new_env/Run2_UTC_lumi_evaluation/testing_prescales/{year}lumi_HLTIsoMu24_byls.csv"
    if(year=="2016"):
        skip_lines_from_foot = 10
    else if(year=="2017"):
        skip_lines_from_foot = 14
    else if(year=="2018"):
        skip_lines_from_foot = 14
    df = pd.read_csv(input_file_name, sep=',',skiprows=1, skipfooter=skip_lines_from_foot, engine='python')  # required when using skipfooter)
    return df

def process_lumi_file(df):
    # Step 2: Remove the hashtag from '#run:fill' if it's there
    df.columns = [col.lstrip('#') for col in df.columns]
    # Step 3: Split 'run:fill' into 'run' and 'fill'
    df[['run', 'fill']] = df['run:fill'].str.split(':', expand=True)
    # First, attempt to split the column into two parts
    ls_split = df['ls'].str.split(':', expand=True)
    
    # Convert the first part to numeric (errors='coerce' will turn non-numeric into NaN)
    first_part = pd.to_numeric(ls_split[0], errors='coerce')
    second_part = pd.to_numeric(ls_split[1], errors='coerce')
    
    # Use second part only if first is NaN or 0
    df['ls_value'] = first_part.where((first_part.notna()) & (first_part != 0), second_part)
    
    # Optionally convert ls to integer if clean
    df['ls_value'] = df['ls_value'].astype('uint64')  # or 'int' if you're sure there's no NaN
    df['run'] = df['run'].astype('uint64')  # or 'int' if you're sure there's no NaN
    df = df.sort_values(by='run', ascending=True)
    # Optional: Drop the original 'run:fill' column if no longer needed
    df = df.drop(columns=['run:fill','time', 'hltpath', 'avgpu', 'source','ls', 'fill'])
    df['delivered(/ub)'] = pd.to_numeric(df['delivered(/ub)'], errors='coerce')
    df['recorded(/ub)'] = pd.to_numeric(df['recorded(/ub)'], errors='coerce')
    # Create cumulative sum columns
    df['int_delivered(/ub)'] = df['delivered(/ub)'].cumsum()
    df['int_recorded(/ub)'] = df['recorded(/ub)'].cumsum()

    return df

def read_root_file(input_name):
    file = uproot.open(input_name)
    tree = file["Events"]  # or your actual TTree name
    df_root = tree.arrays(["Event", "Run", "LumiSect"], library="pd") # , entry_start=0, entry_stop=100)  # event_ti
    #df_root = tree.arrays(["Event", "Run", "LumiSect"], library="pd" , entry_start=0, entry_stop=100)  # event_ti
    return df_root

def MergingHV(df_root, df_HV, year) : 
    intlumi_delivered_to_add = 0
    intlumi_recorded_to_add = 0
    if(year=="2017"):
        intlumi_delivered_to_add =  37.796619062
        intlumi_recorded_to_add =  36.262798807
    elif(year=="2018"):
        intlumi_delivered_to_add =  82.070905
        intlumi_recorded_to_add =  77.894203
    # rename the HV read column so to merge with the current ntuple 
    df_renamed = df_HV.rename(columns={"run": "Run", "ls_value": "LumiSect"})
    #print(df_root[['_runNb', '_lumiBlock']].dtypes)
    #print(df_renamed[['_runNb', '_lumiBlock']].dtypes)
    #print(" after masking for particlular rhid : the dataframe ")
    #print("len of dataframe", df_root)
    merged = pd.merge(df_root, df_renamed, on=["Run", "LumiSect"], how="left")

    merged['int_delivered(/fb)'] = merged['int_delivered(/ub)']/(10**9)
    merged['int_recorded(/fb)'] = merged['int_recorded(/ub)']/(10**9)
    merged.drop(columns=['delivered(/ub)', 'recorded(/ub)', 'int_recorded(/ub)', 'int_delivered(/ub)'], inplace=True)
   
    merged['int_delivered(/fb)'] =  merged['int_delivered(/fb)'] +intlumi_delivered_to_add
    merged['int_recorded(/fb)'] =  merged['int_recorded(/fb)'] +intlumi_recorded_to_add
    #print("merged columns ", merged.columns)
    merged.rename(columns={"int_delivered(/fb)" : "_intlumi_delivered_goldenjson"}, inplace=True)
    merged.rename(columns={"int_recorded(/fb)" : "_intlumi_recorded_goldenjson"}, inplace=True)
    filtered = merged
    print("length after merging and filtereing", len(filtered))  
    # Keep a version of filtered aligned to df_root (drop HVvalue, etc.)
    filtered_aligned = filtered[df_root.columns]
    # Get unmatched rows by subtracting
    unmatched = pd.concat([df_root, filtered_aligned]).drop_duplicates(keep=False)

    print("Unmatched length:", len(unmatched))
    print("Unmatched dataframe")
    print(unmatched)
    # Tag
    filtered["lumifound"] = True
    unmatched = unmatched.copy()
    unmatched["lumifound"] = False
    unmatched["lumivalue"] = np.nan  # Add HVvalue column for compatibility

    return filtered, unmatched 

def Savecsv(df, csv_file):
    df.to_csv(csv_file+".csv", index=False)
def saveFile(df, year) :
    csv_file = f"/eos/home-n/nrawal/CSCAgeing/Run2_Reprocessed/InputZfiles/Input_withoutSelection/OutputFiles/csc_input_{year}_tree_updatedlumi"
    Savecsv(df, csv_file)
    df_RDF = ROOT.RDF.FromCSV(csv_file+".csv")
    print("RDF :",df_RDF)
    # Snapshot it to a ROOT file
    output_file = csv_file+".root"
    df_RDF.Snapshot("tree", output_file)


if __name__ == "__main__" :
    parser = argparse.ArgumentParser()
    parser.add_argument("--year", help="year")
    args = parser.parse_args()
    year = args.year
    input_name = f"/eos/home-n/nrawal/CSCAgeing/Run2_Reprocessed/InputZfiles/Input_withoutSelection/InputFiles/csc_input_{year}_tree.root"
    # Read the root file and update it later
    df_root = read_root_file(input_name)
    
    df_lumi = read_lumi_file(year)
    df_lumi = process_lumi_file(df_lumi)

    final_df, final_df_not_matched = MergingHV(df_root, df_lumi, year)
    print('final file length ', len(final_df))
    print('final file not length ', len(final_df_not_matched))
    not_lumi = final_df[final_df['lumifound']==False]
    
    print("len not found ", len(not_lumi))
    # Save the final dataframe into another root file
    print("saving final root file")
    saveFile(final_df, year)
